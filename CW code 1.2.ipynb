{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division # backward compatibility for python2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.special\n",
    "import operator\n",
    "import random\n",
    "#library for plotting arrays\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# A particularly interesting backend, provided by IPython, is the inline backend. \n",
    "# This is available only for the Jupyter Notebook and the Jupyter QtConsole. \n",
    "# It can be invoked as follows: %matplotlib inline\n",
    "# With this backend, the output of plotting commands is displayed inline \n",
    "# within frontends like the Jupyter notebook, directly below the code cell that produced it. \n",
    "# The resulting plots are inside this notebook, not an external window.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets to read\n",
    "# you can change these when trying out other datasets\n",
    "train_file = \"mnist_train.csv\"\n",
    "test_file = \"mnist_test.csv\"\n",
    "\n",
    "class_index = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Similarity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Within our class we now need code for each of the components of k-NN.\n",
    "#First, lets create a method that will measure the distance between two vectors.\n",
    "def euclidean(instance1, instance2):\n",
    "        '''\n",
    "        Calculates euclidean distance between two instances of data\n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        distance = 0\n",
    "        for val1, val2 in zip(instance1, instance2):            \n",
    "            distance += pow((val1 - val2), 2)\n",
    "        \n",
    "        distance = pow(distance, 1/2)\n",
    "             \n",
    "              \n",
    "        return 1 / (1+ distance)\n",
    "    \n",
    "\n",
    "def manhattan(instance1, instance2):\n",
    "        '''\n",
    "        Calculates manhattan distance between two instances of data\n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        distance = 0\n",
    "        for val1, val2 in zip(instance1, instance2):\n",
    "            distance += abs(val1 - val2)      \n",
    "              \n",
    "        return 1 / (1+ distance)\n",
    "    \n",
    "def dot_product(instance1, instance2):\n",
    "        '''\n",
    "        Calculates dot product between two instances \n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        return np.dot(instance1, instance2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Evaluations Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Finally, we can test to see how many of the test instances we got correct\n",
    "    def accuracy(results):\n",
    "        correct = 0\n",
    "        for predict, target in results:\n",
    "            \n",
    "            if predict == target:\n",
    "                correct += 1\n",
    "        return (correct/float(len(results))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename, class_idx=class_index, split=0.8):\n",
    "    dataframe = pd.read_csv(filename)\n",
    "    sampleSize = 2000\n",
    "    dataframe = dataframe.sample(sampleSize)\n",
    "    instances = dataframe.values\n",
    "    \n",
    "\n",
    "    print (\"Class Index: \"+str(class_idx))\n",
    "    # divide data into label and feature sets.\n",
    "    X = instances[:,1:] # you may need to change these depending on which dataset you are using\n",
    "    Y = instances[:,class_idx] \n",
    "    \n",
    "   \n",
    "    X_train = [] # features for the train set\n",
    "    Y_train = [] # class labels for the train set\n",
    "    X_test = [] # features for the test set\n",
    "    Y_test = [] # class labels for the test set\n",
    "    \n",
    "    # the zip iterator is a neat construct in Python\n",
    "    # it lets you iterate over 2 arrays / lists structures \n",
    "    # importantly it iterates upto the length of the smallest structure of the two \n",
    "    # in our case X and Y will be of same length\n",
    "    for  x, y in zip(X, Y): \n",
    "        if random.random() < split: # Return the next random floating point number in the range [0.0, 1.0) and compare\n",
    "            X_train.append(x)\n",
    "            Y_train.append(y)\n",
    "        else:\n",
    "            X_test.append(x)\n",
    "            Y_test.append(y)       \n",
    "    print(\"train set size: \", len(X_train))       \n",
    "    print(\"test set size: \", len(X_test))\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Index: 0\n",
      "train set size:  1582\n",
      "test set size:  418\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset and maintain the features (X) and class labels (Y) separately  \n",
    "# make sure you understand what the 4 and 0.8 default values are in the call\n",
    "# you may have to modify these depending on the dataset you work with.\n",
    "X_train, Y_train, X_test, Y_test = load_dataset(train_file, 0, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build kNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNN:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    X_train, Y_train : list\n",
    "    these consists of the training set feature values and associated class labels\n",
    "    k : int\n",
    "    specify the number of neighbours\n",
    "    sim : literal\n",
    "    specify the name of the similarity metric (e.g. manhattan, eucliedean)\n",
    "    weighted : Boolean\n",
    "    specify the voting strategy as weighted or not weighted by similarity values\n",
    "  \n",
    "    Attributes\n",
    "    -----------  \n",
    "    Results : list\n",
    "      Target and predicted class labels for the test data.    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, X_train, Y_train, k=3, sim=manhattan, weighted=False):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        \n",
    "        if k <= len(self.X_train):\n",
    "            self.k = k # set the k value for neighbourhood size\n",
    "        else:\n",
    "            self.k = len(self.X_train) # to ensure the get_neighbours dont crash\n",
    "    \n",
    "        self.similarity = sim # specify a sim metric that has been pre-defined e.g. manhattan or euclidean\n",
    "        \n",
    "        self.weighted = weighted # boolean to choose between weighted / unweighted majority voting\n",
    "        \n",
    "        #store results from testing \n",
    "        self.results= []\n",
    "        \n",
    "    #With k-NN, we are interested in finding the k number of points with the greatest similarity \n",
    "    # to the the query or test instance.\n",
    "    def get_neighbours(self, test_instance):\n",
    "        '''\n",
    "        Locate most similar neighbours \n",
    "        X_train will be a containing features (Float) values (i.e. your training data)\n",
    "        Y_train will be the corresponding class labels for each instance in X_train\n",
    "        test_instance will be a List of Float values (i.e. a query instance)\n",
    "        '''\n",
    "        similarities = [] # collection to store the similarities to be computed\n",
    "\n",
    "        for train_instance, y in zip(self.X_train, self.Y_train): #for each member of the training set\n",
    "            sim = self.similarity(test_instance, train_instance) #calculate the similarity to the test instance\n",
    "            \n",
    "            similarities.append((y, sim)) #add the actual label of the example and the computed similarity to a collection \n",
    "        #print(distances)\n",
    "        similarities.sort(key = operator.itemgetter(1), reverse = True) #sort the collection by decreasing similarity\n",
    "        neighbours = [] # holds the k most similar neighbours\n",
    "        for x in range(self.k): #extract the k top indices of the collection for return\n",
    "            neighbours.append(similarities[x])\n",
    "\n",
    "        return neighbours\n",
    "\n",
    "    # given the neighbours make a prediction\n",
    "    # the boolean parameter when set to False will use unweighted majority voting; otherwise weighted majority voting\n",
    "    # weighting can be helpful to break any ties in voting\n",
    "    def predict(self, neighbours):\n",
    "        '''\n",
    "        Summarise a prediction based upon weighted neighbours calculation\n",
    "        '''\n",
    "        class_votes = {}\n",
    "        for x in range(len(neighbours)):\n",
    "            response = neighbours[x][0]\n",
    "            if response in class_votes:\n",
    "                class_votes[response] += (1-self.weighted) + (self.weighted * neighbours[x][1]) #if not weighted simply add 1\n",
    "                #class_votes[response] += [1, neighbours[x][1]][weighted == True] \n",
    "              \n",
    "            else:\n",
    "                class_votes[response] = (1-self.weighted) + (self.weighted * neighbours[x][1])\n",
    "                #class_votes[response] = [1, neighbours[x][1]][weighted == True] \n",
    "                \n",
    "        #print(class_votes)\n",
    "        sorted_votes = sorted(class_votes, key = lambda k: (class_votes[k], k), reverse = True)\n",
    "        #print(sorted_votes)\n",
    "        return sorted_votes[0]\n",
    "    \n",
    "    #iterate through all the test data to calculate accuracy\n",
    "    def test(self, X_test, Y_test):\n",
    "        self.results = [] # store the predictions returned by kNN\n",
    "\n",
    "        for test_instance, target_label in zip(X_test, Y_test):\n",
    "            neighbours = self.get_neighbours(test_instance)\n",
    "            predict_label = self.predict(neighbours)\n",
    "            self.results.append([predict_label, target_label])\n",
    "            #print('> predicted = ', result,', actual = ', test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply kNN to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Accuracy on test set is:  88.99521531100478\n"
     ]
    }
   ],
   "source": [
    "#create an instance of kNN \n",
    "# pass the training instances with their class labels (i.e. X_train and Y_train)\n",
    "# we will use the default kNN class settings for parameters i.e. k=3, sim=manhattan, weighted=False\n",
    "\n",
    "knn = kNN(X_train, Y_train)\n",
    "knn.test(X_test, Y_test) # now get the predictions on the test set\n",
    "\n",
    "print(\"kNN Accuracy on test set is: \", accuracy(knn.results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Experiment with multiple values of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup the kNN instances ...\n",
      "Accuracy  [92.10526315789474, 88.51674641148325, 85.16746411483254, 80.38277511961722, 76.07655502392345, 74.64114832535886]\n",
      "Accuracy  [92.10526315789474, 88.99521531100478, 85.4066985645933, 81.81818181818183, 77.51196172248804, 75.83732057416267]\n",
      "Results from trials... [[92.10526315789474, 88.51674641148325, 85.16746411483254, 80.38277511961722, 76.07655502392345, 74.64114832535886], [92.10526315789474, 88.99521531100478, 85.4066985645933, 81.81818181818183, 77.51196172248804, 75.83732057416267]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Setup the kNN instances ...\")\n",
    "knn_list = []\n",
    "ks = [1, 11, 21, 51, 81, 91] # try a few different values for k\n",
    "is_weighted = [False, True] # try two different forms of voting\n",
    "\n",
    "# iterate over different voting strategies\n",
    "for weighted in is_weighted:\n",
    "    knn_list_element = [] # first set of knns with a specified voting scheme\n",
    "    #iterate over different k values\n",
    "    for k in ks:\n",
    "        #create the different instances of the kNN class\n",
    "        knn = kNN(X_train, Y_train, k, euclidean, weighted)\n",
    "        \n",
    "        knn_list_element.append(knn)\n",
    "        pass\n",
    "    \n",
    "    knn_list.append(knn_list_element)# now append the set of models \n",
    "    pass\n",
    "\n",
    "\n",
    "#lets test the kNNs \n",
    "#iterate through each model and accumilate number of correct predictions\n",
    "knn_results = []\n",
    "knn_result_element = []\n",
    "\n",
    "for knn1 in knn_list:\n",
    "    knn_result_element = []\n",
    "\n",
    "    for knn2 in knn1:\n",
    "        knn2.test(X_test, Y_test)\n",
    "        knn_result_element.append(accuracy(knn2.results))\n",
    "        pass\n",
    "    print(\"Accuracy \", knn_result_element)\n",
    "    knn_results.append(knn_result_element)\n",
    "    pass\n",
    "print(\"Results from trials...\", knn_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot on Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = len(ks) # this is the number of results we want to plot pn the x-axis\n",
    "ind = np.arange(N) \n",
    "\n",
    "performance1 = knn_results[0]\n",
    "performance2 = knn_results[1]\n",
    "\n",
    "width = 0.35 # width of the bar      \n",
    "plt.bar(ind, performance1, width, label='Unweighted')\n",
    "plt.bar(ind + width, performance2, width, label='Weighted')\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('k')\n",
    "plt.title('kNN performance with increasing k')\n",
    "\n",
    "plt.xticks(ind + width / 2, ks)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
