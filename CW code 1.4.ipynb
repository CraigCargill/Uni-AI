{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 - Testing Handwriting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "#for the sigmoid function we need expit() from scipy\n",
    "import scipy.special\n",
    "#library for plotting arrays\n",
    "import matplotlib.pyplot as plt\n",
    "# A particularly interesting backend, provided by IPython, is the inline backend. \n",
    "# This is available only for the Jupyter Notebook and the Jupyter QtConsole. \n",
    "# It can be invoked as follows: %matplotlib inline\n",
    "# With this backend, the output of plotting commands is displayed inline \n",
    "# within frontends like the Jupyter notebook, directly below the code cell that produced it. \n",
    "# The resulting plots are inside this notebook, not an external window.\n",
    "import glob\n",
    "\n",
    "import imageio\n",
    "\n",
    "import pandas as pd # to manage data frames and reading csv files\n",
    "\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of input, hidden and output nodes\n",
    "input_nodes = 784 #we have a 28x28 matrix to describe each digit\n",
    "hidden_nodes = 250\n",
    "output_nodes = 10\n",
    "\n",
    "learning_rate = 0.2\n",
    "batch_size = 3 # increase this if you want batch gradient descent\n",
    "\n",
    "# epochs is the number of training iterations \n",
    "epochs = 20\n",
    "\n",
    "# datasets to read\n",
    "# you can change these when trying out other datasets\n",
    "train_file = \"mnist_train.csv\"\n",
    "test_file = \"mnist_test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "    def backward(self, inputs):\n",
    "        self.output = np.greater(inputs, 0).astype(int) # inputs > 0 then convert bools to int\n",
    "        \n",
    "class Activation_Sigmoid:\n",
    "    def forward(self, x):\n",
    "        return(1 / (1 + np.exp(-x)))\n",
    "    def backward(self, x):\n",
    "        return(x * ( 1 - x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(predictions, targets):\n",
    "    \"\"\"\n",
    "    Calculates mean squared error of a model's predictions.\n",
    "    \"\"\"\n",
    "    N=targets.size\n",
    "    mse = ((targets - predictions) **2).sum() / (2*N)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy of a model's predictions.\n",
    "    \"\"\"\n",
    "    prediction_labels = np.argmax(predictions, axis=1)\n",
    "    target_labels = np.argmax(targets, axis=1)\n",
    "    predictions_correct = (prediction_labels == target_labels.round())\n",
    "    accuracy = predictions_correct.mean()\n",
    "    return accuracy\n",
    "\n",
    "#Finally, we can test to see how many of the test instances we got correct\n",
    "def accuracyknn(results):\n",
    "    correct = 0\n",
    "    for predict, target in results:\n",
    "            \n",
    "        if predict == target:\n",
    "            correct += 1\n",
    "    return (correct/float(len(results))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the mnist training data CSV file into a frame\n",
    "df_orig_train = pd.read_csv(train_file, header=None)  # read entire train dataset\n",
    "df_orig_test = pd.read_csv(test_file, header=None)  # read entire test dataset\n",
    "#df_orig_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(60000, 784)\n",
      "(10000, 10)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "y_train_all =  pd.get_dummies(df_orig_train[0]).values\n",
    "X_train_all = df_orig_train.drop(0, axis = 1).values\n",
    "print(y_train_all.shape)\n",
    "print(X_train_all.shape)\n",
    "\n",
    "y_test_all =  pd.get_dummies(df_orig_test[0]).values\n",
    "X_test_all = df_orig_test.drop(0, axis = 1).values\n",
    "print(y_test_all.shape)\n",
    "print(X_test_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 784)\n",
      "(10000,)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "kNN_y_train_all =  df_orig_train[0].values\n",
    "kNN_X_train_all = df_orig_train.drop(0, axis = 1).values\n",
    "print(kNN_y_train_all.shape)\n",
    "print(kNN_X_train_all.shape)\n",
    "\n",
    "kNN_y_test_all =  df_orig_test[0].values\n",
    "kNN_X_test_all = df_orig_test.drop(0, axis = 1).values\n",
    "print(kNN_y_test_all.shape)\n",
    "print(kNN_X_test_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select smaller samples of the train and test datasets (will execute faster when training our networks than using the entire dataset)\n",
    "train_sample_size = 1500  # choosing a smaller sample instead of the entire dataset\n",
    "random_indices = np.random.choice(range(len(y_train_all)), train_sample_size, replace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 10)\n",
      "(1500, 784)\n",
      "(1500, 10)\n",
      "(100, 10)\n",
      "(100, 784)\n",
      "(100, 10)\n",
      "(100, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_all[random_indices]\n",
    "y_train = y_train_all[random_indices]\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "\n",
    "#preprocessing steps\n",
    "X_train = (X_train / 255.0 * 0.99) + 0.01\n",
    "y_train = y_train + 0.01\n",
    "y_train = np.where(y_train != 1.01, y_train, 0.99)\n",
    "print(y_train.shape)\n",
    "\n",
    "test_sample_size = 100 \n",
    "random_test_indices = np.random.choice(range(len(y_test_all)), test_sample_size, replace = False)\n",
    "X_test = X_test_all[random_test_indices]\n",
    "y_test = y_test_all[random_test_indices]\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_test = (X_test / 255.0 * 0.99) + 0.01\n",
    "y_test = y_test + 0.01\n",
    "y_test = np.where(y_test != 1.01, y_test, 0.99)\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500,)\n",
      "(1500, 784)\n",
      "(1500,)\n",
      "(100,)\n",
      "(100, 784)\n"
     ]
    }
   ],
   "source": [
    "kNN_X_train = kNN_X_train_all[random_indices]\n",
    "kNN_y_train = kNN_y_train_all[random_indices]\n",
    "print(kNN_y_train.shape)\n",
    "print(kNN_X_train.shape)\n",
    "\n",
    "#preprocessing steps\n",
    "kNN_X_train = (kNN_X_train / 255.0 * 0.99) + 0.01\n",
    "kNN_y_train = kNN_y_train\n",
    "print(kNN_y_train.shape)\n",
    "\n",
    "test_sample_size = 100 \n",
    "random_test_indices = np.random.choice(range(len(y_test_all)), test_sample_size, replace = False)\n",
    "kNN_X_test = kNN_X_test_all[random_test_indices]\n",
    "kNN_y_test = kNN_y_test_all[random_test_indices]\n",
    "print(kNN_y_test.shape)\n",
    "print(kNN_X_test.shape)\n",
    "\n",
    "kNN_X_test = (kNN_X_test / 255.0 * 0.99) + 0.01\n",
    "kNN_y_test = kNN_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Custom Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_my_test_data(folder):\n",
    "    # our own image test data set\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # to read jpg change the regex to '/*.jpg'\n",
    "    folder_expr = folder + '/*.png'\n",
    "    print(folder_expr)\n",
    "\n",
    "    for image_file_name in glob.glob(folder_expr): \n",
    "        print (\"loading ... \", image_file_name)\n",
    "\n",
    "        # load image data from png files into an array\n",
    "        img_array = imageio.imread(image_file_name, as_gray=True)\n",
    "        # reshape from 28x28 to list of 784 values, invert values\n",
    "        img_data  = 255.0 - img_array.reshape(784)\n",
    "        # then scale data to range from 0.01 to 1.0\n",
    "        inputs = (img_data / 255.0 * 0.99) + 0.01\n",
    "        \n",
    "        # use the filename to set the correct label\n",
    "        digit_class = int(image_file_name[-5:-4]) #negative indices for indexing from the end of the array\n",
    "        \n",
    "        X.insert(len(X), inputs)\n",
    "        y.insert(len(y), digit_class)\n",
    "       \n",
    "        pass\n",
    "    return(X,y)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_images/*.png\n",
      "loading ...  my_images\\b0.png\n",
      "loading ...  my_images\\b1.png\n",
      "loading ...  my_images\\b2.png\n",
      "loading ...  my_images\\b3.png\n",
      "loading ...  my_images\\b4.png\n",
      "loading ...  my_images\\b5.png\n",
      "loading ...  my_images\\b6.png\n",
      "loading ...  my_images\\b7.png\n",
      "loading ...  my_images\\b8.png\n",
      "loading ...  my_images\\b9.png\n",
      "loading ...  my_images\\c1.png\n",
      "loading ...  my_images\\c2.png\n",
      "loading ...  my_images\\c3.png\n",
      "loading ...  my_images\\c4.png\n",
      "loading ...  my_images\\c5.png\n",
      "loading ...  my_images\\c6.png\n",
      "loading ...  my_images\\c7.png\n",
      "loading ...  my_images\\c8.png\n",
      "loading ...  my_images\\c9.png\n",
      "loading ...  my_images\\n0.png\n",
      "loading ...  my_images\\n1.png\n",
      "loading ...  my_images\\n2.png\n",
      "loading ...  my_images\\n3.png\n",
      "loading ...  my_images\\n4.png\n",
      "loading ...  my_images\\n5.png\n",
      "loading ...  my_images\\n6.png\n",
      "loading ...  my_images\\n7.png\n",
      "loading ...  my_images\\n8.png\n",
      "loading ...  my_images\\n9.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c1690fdca0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_my_test, y_my_test = get_my_test_data('my_images') # my_images is a subfolder in the current folder \n",
    "\n",
    "# lets plot one of the created images that was read into X_my_test\n",
    "# now reshape the 784 features into a 28x28 grid\n",
    "# here asfarray helps to convert values into real numbers\n",
    "image_array = np.asfarray(X_my_test[4]).flatten().reshape((28,28))\n",
    "\n",
    "# print the grid in grey scale\n",
    "plt.imshow(image_array, cmap='Greys', interpolation='None') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate and Convert for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_images/*.png\n",
      "loading ...  my_images\\b0.png\n",
      "loading ...  my_images\\b1.png\n",
      "loading ...  my_images\\b2.png\n",
      "loading ...  my_images\\b3.png\n",
      "loading ...  my_images\\b4.png\n",
      "loading ...  my_images\\b5.png\n",
      "loading ...  my_images\\b6.png\n",
      "loading ...  my_images\\b7.png\n",
      "loading ...  my_images\\b8.png\n",
      "loading ...  my_images\\b9.png\n",
      "loading ...  my_images\\c1.png\n",
      "loading ...  my_images\\c2.png\n",
      "loading ...  my_images\\c3.png\n",
      "loading ...  my_images\\c4.png\n",
      "loading ...  my_images\\c5.png\n",
      "loading ...  my_images\\c6.png\n",
      "loading ...  my_images\\c7.png\n",
      "loading ...  my_images\\c8.png\n",
      "loading ...  my_images\\c9.png\n",
      "loading ...  my_images\\n0.png\n",
      "loading ...  my_images\\n1.png\n",
      "loading ...  my_images\\n2.png\n",
      "loading ...  my_images\\n3.png\n",
      "loading ...  my_images\\n4.png\n",
      "loading ...  my_images\\n5.png\n",
      "loading ...  my_images\\n6.png\n",
      "loading ...  my_images\\n7.png\n",
      "loading ...  my_images\\n8.png\n",
      "loading ...  my_images\\n9.png\n"
     ]
    }
   ],
   "source": [
    "#MNIST dataset assume output_nodes = 10 for the ANN\n",
    "\n",
    "# converts the data to a format that the ANN class can use for training the model\n",
    "# this eseentially , maps a given target class label to an outputs vector (y_vec) thats compatible \n",
    "# with the ANN's output layer. \n",
    "\n",
    "#output_nodes = 10\n",
    "def map_target_to_output_layer(instances, targets):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for inputs, target in zip(instances, targets):\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        y_vec = np.zeros(output_nodes) + 0.01\n",
    "        y_vec[int(target)] = 0.99\n",
    "        #print('output', target)\n",
    "        \n",
    "        X.insert(len(X), inputs) # simply inserting these they are already in the correct format\n",
    "        Y.insert(len(Y), y_vec) # inserting these after the vector mapping\n",
    "        #print(y_vec)\n",
    "    pass\n",
    "    return(X,Y)\n",
    "pass\n",
    "\n",
    "ann_X_my_test, ann_y_my_test = get_my_test_data('my_images')\n",
    "ann_X_my_test, ann_y_my_test = map_target_to_output_layer(ann_X_my_test, ann_y_my_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c1691df0d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_array = np.asfarray(ann_X_my_test[1]).flatten().reshape((28,28))\n",
    "# print the grid in grey scale\n",
    "plt.imshow(image_array, cmap='Greys', interpolation='None') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Similarity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Within our class we now need code for each of the components of k-NN.\n",
    "#First, let's create a method that will measure the distance between two vectors.\n",
    "def euclidean(instance1, instance2):\n",
    "        '''\n",
    "        Calculates euclidean distance between two instances of data\n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        distance = 0\n",
    "        for val1, val2 in zip(instance1, instance2):            \n",
    "            distance += pow((val1 - val2), 2)\n",
    "        \n",
    "        distance = pow(distance, 1/2)\n",
    "             \n",
    "              \n",
    "        return 1 / (1+ distance)\n",
    "    \n",
    "\n",
    "def manhattan(instance1, instance2):\n",
    "        '''\n",
    "        Calculates manhattan distance between two instances of data\n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        distance = 0\n",
    "        for val1, val2 in zip(instance1, instance2):\n",
    "            distance += abs(val1 - val2)      \n",
    "              \n",
    "        return 1 / (1+ distance)\n",
    "    \n",
    "def dot_product(instance1, instance2):\n",
    "        '''\n",
    "        Calculates dot product between two instances \n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        return np.dot(instance1, instance2)\n",
    "    \n",
    "def cosine(instance1, instance2):\n",
    "        cossime = dot(instance1, instance20/(norm(instance1)*norm(instance2)))\n",
    "        return cossime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Layer_Dense to Build Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons, learningrate=0.01, activation='sigmoid'):\n",
    "        \n",
    "        self.weights = np.random.normal(0.0, pow(n_inputs, -0.5), (n_inputs, n_neurons))\n",
    "        print(self.weights.shape)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "       \n",
    "        self.lr = learningrate\n",
    "        self.activate=activation  \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        self.in_values = inputs\n",
    "        self.layer_input = np.dot(inputs , self.weights) + self.biases\n",
    "        self.activation()\n",
    "    \n",
    "    def activation(self):\n",
    "        if self.activate == 'sigmoid':\n",
    "            a = Activation_Sigmoid()\n",
    "            self.layer_output = a.forward(self.layer_input)\n",
    "            \n",
    "           \n",
    "    def del_activation(self):\n",
    "        if self.activate == 'sigmoid':\n",
    "            del_a = Activation_Sigmoid()\n",
    "            self.del_layer_output =  del_a.backward(del_a.forward(self.layer_input))\n",
    "      \n",
    "    def backward(self, delta_in, weights_in, targets=None, output_layer=False):\n",
    "        self.del_activation()\n",
    "        if output_layer:\n",
    "            self.layer_error = self.layer_output - targets\n",
    "            self.layer_delta = self.layer_error * self.del_layer_output\n",
    "        else:          \n",
    "            self.layer_error = np.dot(delta_in, weights_in.T)\n",
    "            self.layer_delta = self.layer_error * self.del_layer_output\n",
    "        \n",
    "    def weight_update(self, prev_layer_output):\n",
    "        # print(\"prev_layer_output.T.shape: \"+str(prev_layer_output.T.shape))\n",
    "        # print(\"self.layer_delta.shape: \"+str(self.layer_delta.shape))\n",
    "        N = self.layer_delta.shape[0]\n",
    "        weights_update = np.dot(prev_layer_output.T, self.layer_delta) / N\n",
    "        # print(weights_update.shape)\n",
    "        self.weights -= self.lr * weights_update\n",
    "        biases_update = np.mean(self.layer_delta, axis=0, keepdims=True)\n",
    "        # print(\"biases_update.shape: \"+ str(biases_update.shape))\n",
    "        # print(\"self.biases.shape: \"+ str(self.biases.shape))\n",
    "        self.biases -= self.lr * biases_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build ANN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN():\n",
    "    def __init__(self, ouput_layer, hidden_layer, batch_size = 10):\n",
    "        self.output = ouput_layer\n",
    "        self.layer1 = hidden_layer\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def batch_input(self, x, y):\n",
    "        for i in range(0, len(x), self.batch_size):\n",
    "            yield (x[i:i + self.batch_size], y[i:i + self.batch_size])\n",
    "\n",
    "    def train(self, x, y, epochs, lr):\n",
    "        self.layer1.lr = lr\n",
    "        self.output.lr = lr\n",
    "\n",
    "        monitoring = {}\n",
    "        monitoring['mean_squared_error'] = []\n",
    "        monitoring['accuracy'] = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for (batch_x, batch_y) in self.batch_input(x, y):\n",
    "                self.layer1.forward(batch_x)\n",
    "                # print('layer1 output \\n' ,layer1.layer_output.shape)\n",
    "                self.output.forward(self.layer1.layer_output)\n",
    "                # print('layer output  \\n', output.layer_output.shape)\n",
    "\n",
    "                # backprop through the layers \n",
    "                self.output.backward(None, None, batch_y, True)\n",
    "                # print('layer out delta  \\n', output.layer_delta.shape)\n",
    "                self.layer1.backward(self.output.layer_delta, self.output.weights)\n",
    "                # print('layer1 delta  \\n', layer1.layer_delta.shape)\n",
    "\n",
    "                # update all the layer weights\n",
    "                self.output.weight_update(self.layer1.layer_output)\n",
    "                # print('layer weights  \\n', output.weights.shape)\n",
    "                self.layer1.weight_update(batch_x)\n",
    "                # print('layer weights  \\n', layer1.weights.shape)\n",
    "            pred = self.predict(x)\n",
    "            mse, acc = self.evaluate(pred, y)\n",
    "            monitoring['mean_squared_error'].append(mse)\n",
    "            monitoring['accuracy'].append(acc)\n",
    "\n",
    "        monitoring_df = pd.DataFrame(monitoring)   \n",
    "        return monitoring_df\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.layer1.forward(x)\n",
    "        self.output.forward(self.layer1.layer_output)\n",
    "        return self.output.layer_output\n",
    "\n",
    "    def evaluate(self, predicts, y):\n",
    "        mse = mean_squared_error(predicts, y)\n",
    "        acc = accuracy(predicts, y)\n",
    "        return mse, acc\n",
    "\n",
    "    def test(self, x, y):\n",
    "        monitoring = {}\n",
    "        pred = self.predict(x)\n",
    "        mse, acc = self.evaluate(pred, y)\n",
    "        monitoring['mean_squared_error'] = [mse]\n",
    "        monitoring['accuracy'] = [acc]\n",
    "        return pd.DataFrame(monitoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build kNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNN:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    X_train, Y_train : list\n",
    "    these consists of the training set feature values and associated class labels\n",
    "    k : int\n",
    "    specify the number of neighbours\n",
    "    sim : literal\n",
    "    specify the name of the similarity metric (e.g. manhattan, eucliedean)\n",
    "    weighted : Boolean\n",
    "    specify the voting strategy as weighted or not weighted by similarity values\n",
    "  \n",
    "    Attributes\n",
    "    -----------  \n",
    "    Results : list\n",
    "      Target and predicted class labels for the test data.    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, X_train, Y_train, k=1, sim=euclidean, weighted=True):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        \n",
    "        if k <= len(self.X_train):\n",
    "            self.k = k # set the k value for neighbourhood size\n",
    "        else:\n",
    "            self.k = len(self.X_train) # to ensure the get_neighbours dont crash\n",
    "    \n",
    "        self.similarity = sim # specify a sim metric that has been pre-defined e.g. manhattan or euclidean\n",
    "        \n",
    "        self.weighted = weighted # boolean to choose between weighted / unweighted majority voting\n",
    "        \n",
    "        #store results from testing \n",
    "        self.results= []\n",
    "        \n",
    "    #With k-NN, we are interested in finding the k number of points with the greatest similarity \n",
    "    # to the the query or test instance.\n",
    "    def get_neighbours(self, test_instance):\n",
    "        '''\n",
    "        Locate most similar neighbours \n",
    "        X_train will be a containing features (Float) values (i.e. your training data)\n",
    "        Y_train will be the corresponding class labels for each instance in X_train\n",
    "        test_instance will be a List of Float values (i.e. a query instance)\n",
    "        '''\n",
    "        similarities = [] # collection to store the similarities to be computed\n",
    "\n",
    "        for train_instance, y in zip(self.X_train, self.Y_train): #for each member of the training set\n",
    "            sim = self.similarity(test_instance, train_instance) #calculate the similarity to the test instance\n",
    "            \n",
    "            similarities.append((y, sim)) #add the actual label of the example and the computed similarity to a collection \n",
    "        #print(distances)\n",
    "        similarities.sort(key = operator.itemgetter(1), reverse = True) #sort the collection by decreasing similarity\n",
    "        neighbours = [] # holds the k most similar neighbours\n",
    "        for x in range(self.k): #extract the k top indices of the collection for return\n",
    "            neighbours.append(similarities[x])\n",
    "\n",
    "        return neighbours\n",
    "\n",
    "    # given the neighbours make a prediction\n",
    "    # the boolean parameter when set to False will use unweighted majority voting; otherwise weighted majority voting\n",
    "    # weighting can be helpful to break any ties in voting\n",
    "    def predict(self, neighbours):\n",
    "        '''\n",
    "        Summarise a prediction based upon weighted neighbours calculation\n",
    "        '''\n",
    "        class_votes = {}\n",
    "        for x in range(len(neighbours)):\n",
    "            response = neighbours[x][0]\n",
    "            if response in class_votes:\n",
    "                class_votes[response] += (1-self.weighted) + (self.weighted * neighbours[x][1]) #if not weighted simply add 1\n",
    "                #class_votes[response] += [1, neighbours[x][1]][weighted == True] \n",
    "              \n",
    "            else:\n",
    "                class_votes[response] = (1-self.weighted) + (self.weighted * neighbours[x][1])\n",
    "                #class_votes[response] = [1, neighbours[x][1]][weighted == True] \n",
    "                \n",
    "        #print(class_votes)\n",
    "        sorted_votes = sorted(class_votes, key = lambda k: (class_votes[k], k), reverse = True)\n",
    "        #print(sorted_votes)\n",
    "        return sorted_votes[0]\n",
    "    \n",
    "    #iterate through all the test data to calculate accuracy\n",
    "    def test(self, X_test, Y_test):\n",
    "        self.results = [] # store the predictions returned by kNN\n",
    "\n",
    "        for test_instance, target_label in zip(X_test, Y_test):\n",
    "            neighbours = self.get_neighbours(test_instance)\n",
    "            predict_label = self.predict(neighbours)\n",
    "            self.results.append([predict_label, target_label])\n",
    "            #print('> predicted = ', result,', actual = ', test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 200)\n",
      "(200, 10)\n",
      "Accuracy  0.3793\n",
      "37.93103448275862\n"
     ]
    }
   ],
   "source": [
    "ann_X_my_test = np.array(ann_X_my_test)\n",
    "ann_y_my_test = np.array(ann_y_my_test)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# set other hyperparameters\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "lr = 0.3\n",
    "\n",
    "# configure the layers\n",
    "hidden = Layer_Dense(784,200)\n",
    "output = Layer_Dense(200,10)\n",
    "\n",
    "# create an ANN model\n",
    "ann = ANN(output, hidden, batch_size)\n",
    "\n",
    "# train the ANN model with training data\n",
    "train_performance = ann.train(X_train, y_train, epochs, lr)\n",
    "\n",
    "train_performance\n",
    "\n",
    "ann_list = []\n",
    "train_performance_list = []\n",
    "\n",
    "# create an ANN model\n",
    "ann = ANN(output, hidden, batch_size)\n",
    "\n",
    "# train the ANN model with training data\n",
    "train_performance = ann.train(X_train, y_train, epochs, lr)\n",
    "train_performance\n",
    "    \n",
    "#test the model\n",
    "df_test_result = ann.test(ann_X_my_test, ann_y_my_test)\n",
    "  \n",
    "acc=df_test_result['accuracy'].values\n",
    "print(\"Accuracy \", '%.4f' % acc[0])\n",
    "annAcc = float(acc[0] * 100)\n",
    "print(annAcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "knn_list = []\n",
    "\n",
    "#create the different instances of the kNN class\n",
    "knn = kNN(kNN_X_train, kNN_y_train, 1, euclidean, True)     \n",
    "knn.test(X_my_test, y_my_test)\n",
    "knn_list.append(knn)# now append the set of models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  37.9310\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \", '%.4f' %  accuracyknn(knn_list[0].results))\n",
    "knnAcc = float(accuracyknn(knn_list[0].results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model ANN vs kNN on Handwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_acc = []\n",
    "combined_acc.append(annAcc)\n",
    "combined_acc.append(knnAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = ['ANN', 'kNN']\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = combined_acc\n",
    "\n",
    "batchsize_axes = plt.gca()\n",
    "batchsize_axes.set_ylim([0,100])\n",
    "\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Handwritten ANN vs kNN')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
