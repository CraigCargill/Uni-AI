{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 - Hybrid Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "#for the sigmoid function we need expit() from scipy\n",
    "import scipy.special\n",
    "#library for plotting arrays\n",
    "import matplotlib.pyplot as plt\n",
    "# A particularly interesting backend, provided by IPython, is the inline backend. \n",
    "# This is available only for the Jupyter Notebook and the Jupyter QtConsole. \n",
    "# It can be invoked as follows: %matplotlib inline\n",
    "# With this backend, the output of plotting commands is displayed inline \n",
    "# within frontends like the Jupyter notebook, directly below the code cell that produced it. \n",
    "# The resulting plots are inside this notebook, not an external window.\n",
    "import glob\n",
    "\n",
    "import imageio\n",
    "\n",
    "import pandas as pd # to manage data frames and reading csv files\n",
    "\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of input, hidden and output nodes\n",
    "input_nodes = 784 #we have a 28x28 matrix to describe each digit\n",
    "hidden_nodes = 250\n",
    "output_nodes = 10\n",
    "\n",
    "learning_rate = 0.2\n",
    "batch_size = 3 # increase this if you want batch gradient descent\n",
    "\n",
    "# epochs is the number of training iterations \n",
    "epochs = 20\n",
    "\n",
    "# datasets to read\n",
    "# you can change these when trying out other datasets\n",
    "train_file = \"mnist_train.csv\"\n",
    "test_file = \"mnist_test.csv\"\n",
    "\n",
    "allAccuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the mnist training data CSV file into a frame\n",
    "df_orig_train = pd.read_csv(train_file, header=None)  # read entire train dataset\n",
    "df_orig_test = pd.read_csv(test_file, header=None)  # read entire test dataset\n",
    "#df_orig_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(60000, 784)\n",
      "(10000, 10)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "y_train_all =  pd.get_dummies(df_orig_train[0]).values\n",
    "X_train_all = df_orig_train.drop(0, axis = 1).values\n",
    "print(y_train_all.shape)\n",
    "print(X_train_all.shape)\n",
    "\n",
    "y_test_all =  pd.get_dummies(df_orig_test[0]).values\n",
    "X_test_all = df_orig_test.drop(0, axis = 1).values\n",
    "print(y_test_all.shape)\n",
    "print(X_test_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 784)\n",
      "(10000,)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "kNN_y_train_all =  df_orig_train[0].values\n",
    "kNN_X_train_all = df_orig_train.drop(0, axis = 1).values\n",
    "print(kNN_y_train_all.shape)\n",
    "print(kNN_X_train_all.shape)\n",
    "\n",
    "kNN_y_test_all =  df_orig_test[0].values\n",
    "kNN_X_test_all = df_orig_test.drop(0, axis = 1).values\n",
    "print(kNN_y_test_all.shape)\n",
    "print(kNN_X_test_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "    def backward(self, inputs):\n",
    "        self.output = np.greater(inputs, 0).astype(int) # inputs > 0 then convert bools to int\n",
    "        \n",
    "class Activation_Sigmoid:\n",
    "    def forward(self, x):\n",
    "        return(1 / (1 + np.exp(-x)))\n",
    "    def backward(self, x):\n",
    "        return(x * ( 1 - x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select smaller samples of the train and test datasets (will execute faster when training our networks than using the entire dataset)\n",
    "train_sample_size = 1500  # choosing a smaller sample instead of the entire dataset\n",
    "random_indices = np.random.choice(range(len(y_train_all)), train_sample_size, replace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 10)\n",
      "(1500, 784)\n",
      "(1500, 10)\n",
      "(100, 10)\n",
      "(100, 784)\n",
      "(100, 10)\n",
      "(100, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_all[random_indices]\n",
    "y_train = y_train_all[random_indices]\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "\n",
    "#preprocessing steps\n",
    "X_train = (X_train / 255.0 * 0.99) + 0.01\n",
    "y_train = y_train + 0.01\n",
    "y_train = np.where(y_train != 1.01, y_train, 0.99)\n",
    "print(y_train.shape)\n",
    "\n",
    "test_sample_size = 100 \n",
    "random_test_indices = np.random.choice(range(len(y_test_all)), test_sample_size, replace = False)\n",
    "X_test = X_test_all[random_test_indices]\n",
    "y_test = y_test_all[random_test_indices]\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_test = (X_test / 255.0 * 0.99) + 0.01\n",
    "y_test = y_test + 0.01\n",
    "y_test = np.where(y_test != 1.01, y_test, 0.99)\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500,)\n",
      "(1500, 784)\n",
      "(1500,)\n",
      "(100,)\n",
      "(100, 784)\n"
     ]
    }
   ],
   "source": [
    "kNN_X_train = kNN_X_train_all[random_indices]\n",
    "kNN_y_train = kNN_y_train_all[random_indices]\n",
    "print(kNN_y_train.shape)\n",
    "print(kNN_X_train.shape)\n",
    "\n",
    "#preprocessing steps\n",
    "kNN_X_train = (kNN_X_train / 255.0 * 0.99) + 0.01\n",
    "print(kNN_y_train.shape)\n",
    "\n",
    "test_sample_size = 100 \n",
    "random_test_indices = np.random.choice(range(len(y_test_all)), test_sample_size, replace = False)\n",
    "kNN_X_test = kNN_X_test_all[random_test_indices]\n",
    "kNN_y_test = kNN_y_test_all[random_test_indices]\n",
    "print(kNN_y_test.shape)\n",
    "print(kNN_X_test.shape)\n",
    "\n",
    "kNN_X_test = (kNN_X_test / 255.0 * 0.99) + 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Within our class we now need code for each of the components of k-NN.\n",
    "#First, let's create a method that will measure the distance between two vectors.\n",
    "def euclidean(instance1, instance2):\n",
    "        '''\n",
    "        Calculates euclidean distance between two instances of data\n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        distance = 0\n",
    "        for val1, val2 in zip(instance1, instance2):            \n",
    "            distance += pow((val1 - val2), 2)\n",
    "        \n",
    "        distance = pow(distance, 1/2)\n",
    "             \n",
    "              \n",
    "        return 1 / (1+ distance)\n",
    "    \n",
    "\n",
    "def manhattan(instance1, instance2):\n",
    "        '''\n",
    "        Calculates manhattan distance between two instances of data\n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        distance = 0\n",
    "        for val1, val2 in zip(instance1, instance2):\n",
    "            distance += abs(val1 - val2)      \n",
    "              \n",
    "        return 1 / (1+ distance)\n",
    "    \n",
    "def dot_product(instance1, instance2):\n",
    "        '''\n",
    "        Calculates dot product between two instances \n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        return np.dot(instance1, instance2)\n",
    "    \n",
    "def cosine(instance1, instance2):\n",
    "        cossime = dot(instance1, instance20/(norm(instance1)*norm(instance2)))\n",
    "        return cossime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(predictions, targets):\n",
    "    \"\"\"\n",
    "    Calculates mean squared error of a model's predictions.\n",
    "    \"\"\"\n",
    "    N=targets.size\n",
    "    mse = ((targets - predictions) **2).sum() / (2*N)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy of a model's predictions.\n",
    "    \"\"\"\n",
    "    prediction_labels = np.argmax(predictions, axis=1)\n",
    "    target_labels = np.argmax(targets, axis=1)\n",
    "    predictions_correct = (prediction_labels == target_labels.round())\n",
    "    accuracy = predictions_correct.mean()\n",
    "    return accuracy\n",
    "\n",
    "#Finally, we can test to see how many of the test instances we got correct\n",
    "def accuracyknn(results):\n",
    "    correct = 0\n",
    "    for predict, target in results:\n",
    "            \n",
    "        if predict == target:\n",
    "            correct += 1\n",
    "    return (correct/float(len(results))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer_Dense Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons, learningrate=0.01, activation='sigmoid'):\n",
    "        \n",
    "        self.weights = np.random.normal(0.0, pow(n_inputs, -0.5), (n_inputs, n_neurons))\n",
    "        print(self.weights.shape)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "       \n",
    "        self.lr = learningrate\n",
    "        self.activate=activation  \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        self.in_values = inputs\n",
    "        self.layer_input = np.dot(inputs , self.weights) + self.biases\n",
    "        self.activation()\n",
    "    \n",
    "    def activation(self):\n",
    "        if self.activate == 'sigmoid':\n",
    "            a = Activation_Sigmoid()\n",
    "            self.layer_output = a.forward(self.layer_input)\n",
    "            \n",
    "           \n",
    "    def del_activation(self):\n",
    "        if self.activate == 'sigmoid':\n",
    "            del_a = Activation_Sigmoid()\n",
    "            self.del_layer_output =  del_a.backward(del_a.forward(self.layer_input))\n",
    "      \n",
    "    def backward(self, delta_in, weights_in, targets=None, output_layer=False):\n",
    "        self.del_activation()\n",
    "        if output_layer:\n",
    "            self.layer_error = self.layer_output - targets\n",
    "            self.layer_delta = self.layer_error * self.del_layer_output\n",
    "        else:          \n",
    "            self.layer_error = np.dot(delta_in, weights_in.T)\n",
    "            self.layer_delta = self.layer_error * self.del_layer_output\n",
    "        \n",
    "    def weight_update(self, prev_layer_output):\n",
    "        # print(\"prev_layer_output.T.shape: \"+str(prev_layer_output.T.shape))\n",
    "        # print(\"self.layer_delta.shape: \"+str(self.layer_delta.shape))\n",
    "        N = self.layer_delta.shape[0]\n",
    "        weights_update = np.dot(prev_layer_output.T, self.layer_delta) / N\n",
    "        # print(weights_update.shape)\n",
    "        self.weights -= self.lr * weights_update\n",
    "        biases_update = np.mean(self.layer_delta, axis=0, keepdims=True)\n",
    "        # print(\"biases_update.shape: \"+ str(biases_update.shape))\n",
    "        # print(\"self.biases.shape: \"+ str(self.biases.shape))\n",
    "        self.biases -= self.lr * biases_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN():\n",
    "    def __init__(self, ouput_layer, hidden_layer, batch_size = 10):\n",
    "        self.output = ouput_layer\n",
    "        self.layer1 = hidden_layer\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def batch_input(self, x, y):\n",
    "        for i in range(0, len(x), self.batch_size):\n",
    "            yield (x[i:i + self.batch_size], y[i:i + self.batch_size])\n",
    "\n",
    "    def train(self, x, y, epochs, lr):\n",
    "        self.layer1.lr = lr\n",
    "        self.output.lr = lr\n",
    "\n",
    "        monitoring = {}\n",
    "        monitoring['mean_squared_error'] = []\n",
    "        monitoring['accuracy'] = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for (batch_x, batch_y) in self.batch_input(x, y):\n",
    "                self.layer1.forward(batch_x)\n",
    "                # print('layer1 output \\n' ,layer1.layer_output.shape)\n",
    "                self.output.forward(self.layer1.layer_output)\n",
    "                # print('layer output  \\n', output.layer_output.shape)\n",
    "\n",
    "                # backprop through the layers \n",
    "                self.output.backward(None, None, batch_y, True)\n",
    "                # print('layer out delta  \\n', output.layer_delta.shape)\n",
    "                self.layer1.backward(self.output.layer_delta, self.output.weights)\n",
    "                # print('layer1 delta  \\n', layer1.layer_delta.shape)\n",
    "\n",
    "                # update all the layer weights\n",
    "                self.output.weight_update(self.layer1.layer_output)\n",
    "                # print('layer weights  \\n', output.weights.shape)\n",
    "                self.layer1.weight_update(batch_x)\n",
    "                # print('layer weights  \\n', layer1.weights.shape)\n",
    "            pred = self.predict(x)\n",
    "            mse, acc = self.evaluate(pred, y)\n",
    "            monitoring['mean_squared_error'].append(mse)\n",
    "            monitoring['accuracy'].append(acc)\n",
    "\n",
    "        monitoring_df = pd.DataFrame(monitoring)   \n",
    "        return monitoring_df\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.layer1.forward(x)\n",
    "        self.output.forward(self.layer1.layer_output)\n",
    "        return self.output.layer_output\n",
    "\n",
    "    def evaluate(self, predicts, y):\n",
    "        mse = mean_squared_error(predicts, y)\n",
    "        acc = accuracy(predicts, y)\n",
    "        return mse, acc\n",
    "\n",
    "    def test(self, x, y):\n",
    "        monitoring = {}\n",
    "        pred = self.predict(x)\n",
    "        mse, acc = self.evaluate(pred, y)\n",
    "        monitoring['mean_squared_error'] = [mse]\n",
    "        monitoring['accuracy'] = [acc]\n",
    "        return pd.DataFrame(monitoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNN:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    X_train, Y_train : list\n",
    "    these consists of the training set feature values and associated class labels\n",
    "    k : int\n",
    "    specify the number of neighbours\n",
    "    sim : literal\n",
    "    specify the name of the similarity metric (e.g. manhattan, eucliedean)\n",
    "    weighted : Boolean\n",
    "    specify the voting strategy as weighted or not weighted by similarity values\n",
    "  \n",
    "    Attributes\n",
    "    -----------  \n",
    "    Results : list\n",
    "      Target and predicted class labels for the test data.    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, X_train, Y_train, k=1, sim=euclidean, weighted=True):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        \n",
    "        if k <= len(self.X_train):\n",
    "            self.k = k # set the k value for neighbourhood size\n",
    "        else:\n",
    "            self.k = len(self.X_train) # to ensure the get_neighbours dont crash\n",
    "    \n",
    "        self.similarity = sim # specify a sim metric that has been pre-defined e.g. manhattan or euclidean\n",
    "        \n",
    "        self.weighted = weighted # boolean to choose between weighted / unweighted majority voting\n",
    "        \n",
    "        #store results from testing \n",
    "        self.results= []\n",
    "        \n",
    "    #With k-NN, we are interested in finding the k number of points with the greatest similarity \n",
    "    # to the the query or test instance.\n",
    "    def get_neighbours(self, test_instance):\n",
    "        '''\n",
    "        Locate most similar neighbours \n",
    "        X_train will be a containing features (Float) values (i.e. your training data)\n",
    "        Y_train will be the corresponding class labels for each instance in X_train\n",
    "        test_instance will be a List of Float values (i.e. a query instance)\n",
    "        '''\n",
    "        similarities = [] # collection to store the similarities to be computed\n",
    "\n",
    "        for train_instance, y in zip(self.X_train, self.Y_train): #for each member of the training set\n",
    "            sim = self.similarity(test_instance, train_instance) #calculate the similarity to the test instance\n",
    "            \n",
    "            similarities.append((y, sim)) #add the actual label of the example and the computed similarity to a collection \n",
    "        #print(distances)\n",
    "        similarities.sort(key = operator.itemgetter(1), reverse = True) #sort the collection by decreasing similarity\n",
    "        neighbours = [] # holds the k most similar neighbours\n",
    "        for x in range(self.k): #extract the k top indices of the collection for return\n",
    "            neighbours.append(similarities[x])\n",
    "\n",
    "        return neighbours\n",
    "\n",
    "    # given the neighbours make a prediction\n",
    "    # the boolean parameter when set to False will use unweighted majority voting; otherwise weighted majority voting\n",
    "    # weighting can be helpful to break any ties in voting\n",
    "    def predict(self, neighbours):\n",
    "        '''\n",
    "        Summarise a prediction based upon weighted neighbours calculation\n",
    "        '''\n",
    "        class_votes = {}\n",
    "        for x in range(len(neighbours)):\n",
    "            response = neighbours[x][0]\n",
    "            if response in class_votes:\n",
    "                class_votes[response] += (1-self.weighted) + (self.weighted * neighbours[x][1]) #if not weighted simply add 1\n",
    "                #class_votes[response] += [1, neighbours[x][1]][weighted == True] \n",
    "              \n",
    "            else:\n",
    "                class_votes[response] = (1-self.weighted) + (self.weighted * neighbours[x][1])\n",
    "                #class_votes[response] = [1, neighbours[x][1]][weighted == True] \n",
    "                \n",
    "        #print(class_votes)\n",
    "        sorted_votes = sorted(class_votes, key = lambda k: (class_votes[k], k), reverse = True)\n",
    "        #print(sorted_votes)\n",
    "        return sorted_votes[0]\n",
    "    \n",
    "    #iterate through all the test data to calculate accuracy\n",
    "    def test(self, X_test, Y_test):\n",
    "        self.results = [] # store the predictions returned by kNN\n",
    "\n",
    "        for test_instance, target_label in zip(X_test, Y_test):\n",
    "            neighbours = self.get_neighbours(test_instance)\n",
    "            predict_label = self.predict(neighbours)\n",
    "            self.results.append([predict_label, target_label])\n",
    "            #print('> predicted = ', result,', actual = ', test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 200)\n",
      "(200, 10)\n",
      "ANN Accuracy is  93.0 %\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# set other hyperparameters\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "lr = 0.3\n",
    "\n",
    "# configure the layers\n",
    "hidden = Layer_Dense(784,200)\n",
    "output = Layer_Dense(200,10)\n",
    "\n",
    "# create an ANN model\n",
    "ann = ANN(output, hidden, batch_size)\n",
    "\n",
    "# train the ANN model with training data\n",
    "train_performance = ann.train(X_train, y_train, epochs, lr)\n",
    "\n",
    "train_performance\n",
    "\n",
    "ann_list = []\n",
    "train_performance_list = []\n",
    "\n",
    "# create an ANN model\n",
    "ann = ANN(output, hidden, batch_size)\n",
    "\n",
    "# train the ANN model with training data\n",
    "train_performance = ann.train(X_train, y_train, epochs, lr)\n",
    "train_performance\n",
    "\n",
    "#test the model\n",
    "df_test_result = ann.test(X_test, y_test)\n",
    "  \n",
    "mse=df_test_result['mean_squared_error'].values\n",
    "acc=df_test_result['accuracy'].values\n",
    "print(\"ANN Accuracy is \", acc[0] * 100, \"%\")\n",
    "#print(\"mse \", mse)\n",
    "    \n",
    "    \n",
    "ann_list.append(ann)\n",
    "allAccuracies.append(acc[0] * 100)\n",
    "train_performance_list.append(train_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Accuracy of kNN on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Accuracy is:  93.0 %\n"
     ]
    }
   ],
   "source": [
    "knn = kNN(kNN_X_train, kNN_y_train, 1, euclidean, True)\n",
    "knn.test(kNN_X_test, kNN_y_test)\n",
    "\n",
    "allAccuracies.append(accuracyknn(knn.results))\n",
    "print(\"kNN Accuracy is: \", accuracyknn(knn.results), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access hidden layer of ann model\n",
    "hidden_layer = ann.layer1 #200 hidden layer\n",
    "\n",
    "#call forward function on that layer for each x value in that training set\n",
    "hy_train_x = []\n",
    "hy_test_x = []\n",
    "\n",
    "for data in kNN_X_train:\n",
    "    hidden_layer.forward(data)\n",
    "    result = hidden_layer.layer_output[0]\n",
    "    hy_train_x.append(result)\n",
    "    pass\n",
    "\n",
    "for data in kNN_X_test:\n",
    "    hidden_layer.forward(data)\n",
    "    result = hidden_layer.layer_output[0]\n",
    "    hy_test_x.append(result)\n",
    "    pass\n",
    "\n",
    "hy = kNN(hy_train_x, kNN_y_train, 1, euclidean, False)\n",
    "hy.test(hy_test_x, kNN_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Accuracy is:  95.0 %\n"
     ]
    }
   ],
   "source": [
    "allAccuracies.append(accuracyknn(hy.results))\n",
    "print(\"Hybrid Accuracy is: \", accuracyknn(hy.results), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[93.0, 93.0, 95.0]\n"
     ]
    }
   ],
   "source": [
    "print(allAccuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAATSklEQVR4nO3df7xldV3v8ddbBp0RNEAGHiDIWBGKlb9GIs1fIBohgqkBhUzlI243f4H5g6wb6g2vpf1CeoRI4ZgIFyEuZKXQ6OSPzBx+ZCoaKMSvAQ6JpAgI+rl/7HXu3bPnnDN7zsw6+xy+r+fjsR97r/Vd67s+57HO473W/u619k5VIUlqx8MmXYAkaWEZ/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH41aQkH0jye5OuY6EleVuSD23lOl9O8rxZ2p6X5ObtUZsWjsGvbZZkfZK7kjxiZP4HklSSg4bm/WiSGln3viT7Ds17QZIbFqT4GSzmumc6YCVZ1dW7rI9tVtWTqmp9H31rMgx+bZMkq4BnAwW8ZIZFvgls6cz6HuB/bN/KttlSrXu76etAoskz+LWtTgD+GfgAsGaG9rXATyZ57hx9nA4cl+RHt7SxJGcmec/IvEuSvKF7/ZYktyT5dpKvJTl0jD4fleSTSU5PkqVS9yzbeUaS24dDO8nLklw9tNjyJP+729aVSZ48tOwNXS1fBO5Jsqyb94KufUX3ruOuJF8BnjGfOjVZBr+21QnAud3jRUn2HGn/LvBO4LQ5+rgFeD/wtjG292HgmOmATrIr8ELg/CQHAK8BnlFVjwJeBNwwV2dJHgOsAz5bVa+r//8dJou67tlU1ReA/wQOG5p9PPBXQ9NHAR8Bduvq+j9JdhxqPw44Atilqh4c2cSpwI90jxcx88Fei5zBr3lL8jPAfsAFVXUF8HXgF2dY9H3A45IcPkd3/ws4MsmTtrDZTzMYVnp2N/1y4HNVdSvwfeARwIFJdqyqG6rq63P0tTfwj8BHqup3llDdb0zyrekH8MWR9rUMwp4kuzEI6A8PtV9RVRdW1QPAHwHLgYOH2k+vqpuq6t4Ztv0LwGlV9c2quonBux4tMQa/tsUa4LKqurOb/jAznAFW1f3A/+weGW3vlpkCzgDeMdcGuzPy8xmclcLgQHNu13YdcBKDM/A7kpyfZO85ujsCWAGcOcu2Fmvd76mqXaYfwE+OtH+IwcFoZwZB/emq2jjUftNQXT8AbmZwENysfQZ7j7T/xxzLapEy+DUvSVYwCJXnJrktyW3AycCTh8eMh5wD/BDw0jm6fTfwfODpW9j8ecDLk+wH/BRw0XRDVX24qqbfiRTw+3P0837gY8DfJdlplmUWY91zqqpbgM91Nb+STYd5AIavRHoYsA9w63AXc3S/cXh94HHzrVOTY/Brvo5mMERxIPCU7vFEBkMaJ4wu3I0Vvw14y2wdVtW3gD8E3jzXhqvqKmAKOBv4eLceSQ5Ickh3Wel9wL1djXN5DfA14KPdwWyp1L0lH+zq+Qng4pG2pyf5+e4D4JOA+xl8QD+OC4DfSrJrkn2A125jnZoAg1/ztQY4p6purKrbph8Mhj1+aZZLAc9jcMY4lz9lvNA7D3gBm45dPwJ4F3AncBuwB/DWuTrphmBOZDB8cUmS5Uuh7jFczODdw8VVdc9I2yXAMcBdDN4R/Hw33j+OtzMY3rkeuIzN301oCYg/xCI9NCX5OvDfquofJl2LFhfP+KWHoCQvYzBW/4lJ16LFxzvzpIeYJOsZfPbyyu6qHWkTDvVIUmMc6pGkxiyJoZ7dd9+9Vq1aNekyJGlJueKKK+6sqpWj85dE8K9atYoNGzZMugxJWlKSzHhntUM9ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmCVx566kxe2PL//3SZfwkHXyYT+23fv0jF+SGmPwS1JjDH5JasxDfozfscf+9DH2CO6zPvW1z7S0eMYvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqTK/Bn+TkJF9O8qUk5yVZnmS3JJcnubZ73rXPGiRJm+ot+JM8FngdsLqqfhzYATgWOAVYV1X7A+u6aUnSAul7qGcZsCLJMuCRwK3AUcDarn0tcHTPNUiShvQW/FV1C/Ae4EZgI3B3VV0G7FlVG7tlNgJ7zLR+khOTbEiyYWpqqq8yJak5fQ717Mrg7P7xwN7ATkmOH3f9qjqrqlZX1eqVK1f2VaYkNafPoZ4XANdX1VRVPQD8NfBM4PYkewF0z3f0WIMkaUSfwX8jcHCSRyYJcChwDXApsKZbZg1wSY81SJJGLOur46r6fJILgSuBB4GrgLOAnYELkryKwcHhFX3VIEnaXG/BD1BVpwKnjsy+n8HZvyRpArxzV5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JakyvwZ9klyQXJvlqkmuS/HSS3ZJcnuTa7nnXPmuQJG2q7zP+PwU+VlVPAJ4MXAOcAqyrqv2Bdd20JGmB9Bb8SR4NPAf4C4Cq+l5VfQs4CljbLbYWOLqvGiRJm+vzjP+HgSngnCRXJTk7yU7AnlW1EaB73mOmlZOcmGRDkg1TU1M9lilJbekz+JcBTwP+vKqeCtzDVgzrVNVZVbW6qlavXLmyrxolqTlbDP4kL04ynwPEzcDNVfX5bvpCBgeC25Ps1fW9F3DHPPqWJM3TOIF+LHBtkj9I8sRxO66q24CbkhzQzToU+ApwKbCmm7cGuGQr6pUkbaNlW1qgqo7vPqg9jsF4fQHnAOdV1be3sPprgXOTPBz4BvArDA42FyR5FXAj8Ipt+QMkSVtni8EPUFX/leQiYAVwEvBS4E1JTq+q986x3tXA6hmaDt36UiVJ28M4Y/xHJrkY+ASwI3BQVR3O4Lr8N/ZcnyRpOxvnjP8VwB9X1aeGZ1bVd5P8aj9lSZL6Mk7wnwpsnJ5IsoLBtfg3VNW63iqTJPVinKt6PgL8YGj6+908SdISNE7wL6uq701PdK8f3l9JkqQ+jRP8U0leMj2R5Cjgzv5KkiT1aZwx/l9ncC3+GUCAm4ATeq1KktSbcW7g+jpwcJKdgYxx05YkaREb6wauJEcATwKWJwGgqt7RY12SpJ6McwPXmcAxDL5+IQyu69+v57okST0Z58PdZ1bVCcBdVfV24KeBffstS5LUl3GC/77u+btJ9gYeAB7fX0mSpD6NM8b/N0l2Ad4NXAkU8P4+i5Ik9WfO4O9+gGVd91u5FyX5KLC8qu5eiOIkSdvfnEM9VfUD4A+Hpu839CVpaRtnjP+yJC/L9HWckqQlbZwx/jcAOwEPJrmPwSWdVVWP7rUySVIvxrlz91ELUYgkaWFsMfiTPGem+aM/zCJJWhrGGep509Dr5cBBwBXAIb1UJEnq1ThDPUcOTyfZF/iD3iqSJPVqnKt6Rt0M/Pj2LkSStDDGGeN/L4O7dWFwoHgK8K891iRJ6tE4Y/wbhl4/CJxXVZ/tqR5JUs/GCf4Lgfuq6vsASXZI8siq+m6/pUmS+jDOGP86YMXQ9ArgH/opR5LUt3GCf3lVfWd6onv9yP5KkiT1aZzgvyfJ06YnkjwduLe/kiRJfRpnjP8k4CNJbu2m92LwU4ySpCVonBu4vpDkCcABDL6g7atV9UDvlUmSejHOj62/Gtipqr5UVf8G7JzkN/ovTZLUh3HG+H+t+wUuAKrqLuDXeqtIktSrcYL/YcM/wpJkB+Dh/ZUkSerTOB/ufhy4IMmZDL664deBv++1KklSb8Y5438Lg5u4/jvwauCLbHpD15y6O32v6n6onSS7Jbk8ybXd867zKVySND9bDP7uB9f/GfgGsBo4FLhmK7bx+pHlTwHWVdX+DA4op2xFX5KkbTRr8Cf5sSS/m+Qa4AzgJoCqen5VnTFO50n2AY4Azh6afRSwtnu9Fjh6HnVLkuZprjH+rwKfBo6squsAkpy8lf3/CfBmYPh3e/esqo0AVbUxyR5b2ackaRvMNdTzMuA24JNJ3p/kUAY3cI0lyYuBO6rqivkUluTEJBuSbJiamppPF5KkGcwa/FV1cVUdAzwBWA+cDOyZ5M+TvHCMvp8FvCTJDcD5wCFJPgTcnmQvgO75jlm2f1ZVra6q1StXrtyav0mSNIdxPty9p6rOraoXA/sAVzPGB7JV9VtVtU9VrQKOBT5RVccDlwJrusXWAJfMs3ZJ0jxs1W/uVtU3q+p9VXXINmzzXcBhSa4FDuumJUkLZJwbuLZZVa1nMFxEVf0ng0tCJUkTsFVn/JKkpc/gl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktSY3oI/yb5JPpnkmiRfTvL6bv5uSS5Pcm33vGtfNUiSNtfnGf+DwG9W1ROBg4FXJzkQOAVYV1X7A+u6aUnSAukt+KtqY1Vd2b3+NnAN8FjgKGBtt9ha4Oi+apAkbW5BxviTrAKeCnwe2LOqNsLg4ADsMcs6JybZkGTD1NTUQpQpSU3oPfiT7AxcBJxUVf817npVdVZVra6q1StXruyvQElqTK/Bn2RHBqF/blX9dTf79iR7de17AXf0WYMkaVN9XtUT4C+Aa6rqj4aaLgXWdK/XAJf0VYMkaXPLeuz7WcArgX9LcnU3763Au4ALkrwKuBF4RY81SJJG9Bb8VfUZILM0H9rXdiVJc/POXUlqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTETCf4kP5vka0muS3LKJGqQpFYtePAn2QH4M+Bw4EDguCQHLnQdktSqSZzxHwRcV1XfqKrvAecDR02gDklq0rIJbPOxwE1D0zcDPzW6UJITgRO7ye8k+doC1LYY7A7cOekixvGGSRewOCyZ/QXus05L+2y/mWZOIvgzw7zabEbVWcBZ/ZezuCTZUFWrJ12HxuP+WnrcZ5MZ6rkZ2Hdoeh/g1gnUIUlNmkTwfwHYP8njkzwcOBa4dAJ1SFKTFnyop6oeTPIa4OPADsBfVtWXF7qORay54a0lzv219DS/z1K12fC6JOkhzDt3JakxBr8kNcbgX0BJXpqkkjyhm17VTb92aJkzkvxy9/oDSW5J8ohuevckN0yi9hZ1++dLI/Oe1+2zI4fmfTTJ87rX65NsGGpbnWT9ApXcjCTfGZn+5SRnbGGd9Um2eBlnt89On6XthiS7b121i4/Bv7COAz7D4EqmaXcAr++ucJrJ94Ff7bswbZWbgd+eo32PJIcvVDHafpIsq6oNVfW6SdfSJ4N/gSTZGXgW8Co2Df4pYB2wZpZV/wQ4OckkbrZTJ8kPJ7kKeAbwr8DdSQ6bZfF3A7+zYMXp/0nyqCTXJ9mxm350d5a+Y7fI8Un+KcmXkhzULfO2JGcluQz4YPeu7qNd22OSXJbkqiTvY+YbUJccg3/hHA18rKr+HfhmkqcNtb0L+M3uC+xG3cjgXcIr+y9RM0lyAHAR8CsM7kMB+D1mD/fPAfcnef4ClNeqFUmunn4A7wCoqm8D64EjuuWOBS6qqge66Z2q6pnAbwB/OdTf04GjquoXR7ZzKvCZqnoqg/uNHtfHH7PQDP6FcxyDL6Sjez5uuqGqrgf+BRj9p5v2TuBNuL8mYSVwCXB8VV09PbOqPg2Q5NmzrDfXgUHb7t6qesr0A/jdobazGRyk6Z7PGWo7D6CqPgU8Osku3fxLq+reGbbzHOBD3Tp/C9y13f6CCTJIFkCSxwCHAGd3H86+CTiGTd82vhN4CzPsk6q6Drga+IW+a9Vm7mbwpYLPmqHtNGYZ66+qTwDLgYP7K00zqarPAquSPBfYoaqGP6AfvXFpevqeubrcnvUtBgb/wng58MGq2q+qVlXVvsD1DL6nCICq+irwFeDFs/RxGvDG3ivVqO8xGKY7Ickm78iq6jJgV+DJs6x7GvDmXqvTbD7I4Oz+nJH5xwAk+Rng7qq6ewv9fAr4pW6dwxns7yXP4F8YxwEXj8y7CHjryLzTGDoYDOu+1uLK7V+atqSq7mFwQD4Z+KGR5rn22d8x+PBeC+9cBiF93sj8u5L8E3AmgwsttuTtwHOSXAm8kMFnbkueX9kg6SEnycsZfFjrRREz8BJBSQ8pSd7L4Kddf27StSxWnvFLUmMc45ekxhj8ktQYg1+SGmPwS1JjDH5Jasz/BURBQMHlUyYQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = ('ANN', 'kNN', 'Hybrid')\n",
    "y = np.arange(len(objects))\n",
    "\n",
    "plt.bar(y, allAccuracies, alpha=0.5)\n",
    "plt.xticks(y, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('ANN vs kNN vs Hybrid')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
